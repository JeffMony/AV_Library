name: DiViDe-MRSSSL-DivideHead-NOUP

num_epochs: 30
l_num_epochs: 0
warmup_epochs: 2.5
ema: true
save_model: true
batch_size: 16
num_workers: 6

need_upsampled: false
need_feat: true
need_fused: false

wandb:
    project_name: VQA_Experiments_2022

data:
    train:
        type: FusionDataset
        args:
            phase: train
            random_crop: false
            anno_file: ./examplar_data_labels/train_labels.txt
            data_prefix: ../datasets/LSVQ
            sample_types:
                #fragments_up:
                #    fragments_h: 8
                #    fragments_w: 8
                #    fsize_h: 32
                #    fsize_w: 32
                #    aligned: 32
                #resize_up:
                #    size_h: 256
                #    size_w: 256
                fragments:
                    fragments_h: 8
                    fragments_w: 8
                    fsize_h: 16
                    fsize_w: 16
                    aligned: 32
                resize:
                    size_h: 128
                    size_w: 128
            clip_len: 32
            frame_interval: 2
            num_clips: 1
    val:
        type: FusionDataset
        args:
            phase: test
            anno_file: ./examplar_data_labels/LIVE_VQC/labels.txt
            data_prefix: ../datasets/LIVE_VQC
            #data_backend: ceph
            sample_types:
                ## During test, we do not need the upsampled samples.
                fragments:
                    fragments_h: 8
                    fragments_w: 8
                    fsize_h: 16
                    fsize_w: 16
                    aligned: 32
                resize:
                    size_h: 128
                    size_w: 128
            clip_len: 32
            frame_interval: 2
            num_clips: 4
model:
    type: DiViDeAddEvaluator
    args:
        divide_head: true # if true, different branches will not share head
        vqa_head:
            in_channels: 768
            hidden_channels: 64
            
optimizer:
    lr: !!float 1e-3
    backbone_lr_mult: !!float 1e-1
    wd: 0.05
        
load_path: ../model_baselines/NetArch/swin_tiny_patch244_window877_kinetics400_1k.pth
test_load_path: ./pretrained_weights/DiViDe-MRSSSL-DivideHead-BiLearn_s_dev_v0.0.pth



    
        
