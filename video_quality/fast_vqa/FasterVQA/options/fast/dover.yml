name: DOVER_Base
num_epochs: 30
l_num_epochs: 0
warmup_epochs: 2.5
ema: true
save_model: true
batch_size: 16
num_workers: 8

wandb:
    project_name: VQA_Experiments_2022

data:
    train:
        type: FusionDataset
        args:
            phase: train
            anno_file: ./examplar_data_labels/train_labels.txt
            data_prefix: ../datasets/LSVQ
            sample_types:
                fragments:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 1
                resize:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 1
                    
    val-livevqc:
        type: FusionDataset
        args:
            phase: test
            anno_file: ./examplar_data_labels/LIVE_VQC/labels.txt
            data_prefix: ../datasets/LIVE_VQC/
            sample_types:
                #resize:
                #    size_h: 224
                #    size_w: 224
                fragments:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                resize:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1
                    
    val-kv1k:
        type: FusionDataset
        args:
            phase: test
            anno_file: ./examplar_data_labels/KoNViD/labels.txt
            data_prefix: ../datasets/KoNViD/
            sample_types:
                fragments:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                resize:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1
    val-ltest:
        type: FusionDataset
        args:
            phase: test
            anno_file: ./examplar_data_labels/LSVQ/labels_test.txt
            data_prefix: ../datasets/LSVQ/
            sample_types:
                #resize:
                #    size_h: 224
                #    size_w: 224
                fragments:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                resize:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1
    val-l1080p:
        type: FusionDataset
        args:
            phase: test
            anno_file: ./examplar_data_labels/LSVQ/labels_1080p.txt
            data_prefix: ../datasets/LSVQ/
            sample_types:
                #resize:
                #    size_h: 224
                #    size_w: 224
                fragments:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                resize:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1

    val-cvd2014:
        type: FusionDataset
        args:
            phase: test
            anno_file: ./examplar_data_labels/CVD2014/labels.txt
            data_prefix: ../datasets/CVD2014/
            sample_types:
                fragments:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                resize:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1
    val-ytugc:
        type: FusionDataset
        args:
            phase: test
            anno_file: ./examplar_data_labels/YouTubeUGC/labels.txt
            data_prefix: ../datasets/YouTubeUGC/
            sample_types:
                fragments:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 3
                resize:
                    size_h: 224
                    size_w: 224
                    clip_len: 32
                    frame_interval: 2
                    t_frag: 32
                    num_clips: 1
                    





model:
    type: DiViDeAddEvaluator
    args:
        backbone:
            fragments:
                type: swin_tiny_grpb
                checkpoint: false
                pretrained:
            resize:
                type: conv_tiny
        backbone_preserve_keys: fragments,resize
        divide_head: true
        vqa_head:
            in_channels: 768
            hidden_channels: 64
            
optimizer:
    lr: !!float 1e-3
    backbone_lr_mult: !!float 1e-1
    wd: 0.05
        
load_path: ../pretrained/swin_tiny_patch244_window877_kinetics400_1k.pth
test_load_path: ./pretrained_weights/FAST_VQA_B_1*4.pth
test_load_path_aux: ./pretrained_weights/DOVER-QoC-Branch-ConvNeXt-32-UFrames_val-livevqc_s_dev_v0.0.pth

    
        
