name: FAST-VQA-with-Conv-Backbone-Resize-MultiLevel

num_epochs: 60
l_num_epochs: 10
warmup_epochs: 2.5
ema: true
save_model: true
batch_size: 16
num_workers: 6

need_upsampled: false
need_feat: false
need_fused: false

wandb:
    project_name: VQA_Experiments_2022

data:
    train_kv1k:
        type: FusionDataset
        args:
            phase: train
            random_crop: false
            #anno_file: ./examplar_data_labels/train_labels.txt
            #data_prefix: ../datasets/LSVQ
            anno_file: ./examplar_data_labels/KoNViD/labels.txt
            data_prefix: ../datasets/KoNViD
            sample_types:
                resize:
                    size_h: 224
                    size_w: 224
            clip_len: 16
            frame_interval: 6
            num_clips: 1
    train_livevqc:
        type: FusionDataset
        args:
            phase: train
            random_crop: false
            #anno_file: ./examplar_data_labels/train_labels.txt
            #data_prefix: ../datasets/LSVQ
            anno_file: ./examplar_data_labels/LIVE_VQC/labels.txt
            data_prefix: ../datasets/LIVE_VQC
            sample_types:
                resize:
                    size_h: 224
                    size_w: 224
            clip_len: 16
            frame_interval: 6
            num_clips: 1
    train:
        type: FusionDataset
        args:
            phase: train
            random_crop: false
            #anno_file: ./examplar_data_labels/train_labels.txt
            #data_prefix: ../datasets/LSVQ
            anno_file: ./examplar_data_labels/mgtv_training.txt
            data_prefix: ../mgtv_vqa/MGTV_VQA_DATA/1.MGTV_OGC_V1_dataset/training
            sample_types:
                resize:
                    size_h: 224
                    size_w: 224
            clip_len: 16
            frame_interval: 6
            num_clips: 1
    val:
        type: FusionDataset
        args:
            phase: test
            #anno_file: ./examplar_data_labels/LIVE_VQC/labels.txt
            #data_prefix: ../datasets/LIVE_VQC
            anno_file: ./examplar_data_labels/mgtv_validation.txt
            data_prefix: ../mgtv_vqa/MGTV_VQA_DATA/1.MGTV_OGC_V1_dataset/validation
            sample_types:
                resize:
                    size_h: 224
                    size_w: 224
            clip_len: 16
            frame_interval: 6
            num_clips: 2
model:
    type: DiViDeAddEvaluator
    args:
        backbone_size: conv_tiny
        backbone_preserve_keys: resize
        divide_head: true # if true, different branches will not share head
        vqa_head:
            in_channels: 768
            hidden_channels: 64
            
optimizer:
    lr: !!float 1e-3
    backbone_lr_mult: !!float 1e-1
    wd: 0.05
        
#load_path: ./pretrained_weights/FAST-VQA-with-Conv-Backbone-Resize_s_dev_v0.0.pth
test_load_path: ./pretrained_weights/FAST-VQA-with-Conv-Backbone-Resize-SN_n_dev_v0.0.pth




    
        

